---
title: "Airline Loyalty Causal Inference"
subtitle: "By: Rebecca Hull"
format: revealjs
license: "CC BY-SA 4.0"
---

## Motivation

I've always loved airplanes. 

I'm investigating how attaining a loyalty card status with an airline impacts CLV. Customer Lifetime Value (CLV) is calculated as the total revenue generated by a customer from flight bookings throughout their membership period. Basically, it represents the expected total revenue from a given customer.

I believe that having a loyalty card increases CLV.

## Business Problem and Data

**Does getting a higher loyalty card status (Star or Nova) cause an increase in CLV?**

The data comes from Kaggle and contains information such as loyalty card type, CLV, salary, education level, marital status, total flights, and enrollment year/month. Everyone in the dataset has at least Aurora but some have Nova and some have even higher still with Star.

## Executive Summary


## Data Structure

![](../figures/data_structure.png){width=100%}

## Exploratory Data Analysis

![](../figures/clv_histogram.png){width=100%}

## Exploratory Data Analysis

![](../figures/enrollment_type_bar_chart.png){width=100%}

## Exploratory Data Analysis

![](../figures/loyalty_card_distribution_bar_chart.png){width=100%}

## Exploratory Data Analysis

![](../figures/salary_histogram.png){width=100%}

## DAG

![](../figures/DAG_CLV.jpg){width=100%}


## Identification Strategy

- There were a total of 23 different paths (irrespective of arrow directionality) from Loyalty Card Status to CLV.

- Identified backdoor paths and created adjustment set.

- In order to do causal inference, my model will need to include: Loyalty Card Status, CLV, Income, Travel Frequency, Company Marketing Strategy, and Customer Engagement. (These last 4 will need to be conditioned on.)

## Practice: Simulate Data and Recover Parameters

- Step 1: Import needed libraries.

- Step 2: Define variables and set them equal to a value.

- Step 3: Simulate predictors randomly using uniform distributions. Use predictors and parameter values to simulate the outcome in multiple linear regression format.

- Step 4: Create and train the linear regression model.

- Step 5: Have you recovered the parameters?

Next slide has code & results

## Parameters I set matched what I got back

![](../figures/parameters.png){width=100%}


## Estimate My Causal Effects

What my code does:

- Defines a Bayesian regression model where CLV is predicted using the generated features.

- Uses normal priors for the intercept and regression coefficients.

- Uses a half-normal prior for the noise (sigma).

- Estimates the posterior distribution of model parameters using MCMC sampling.

- Summarizes the posterior distributions of parameters and plots the marginal posterior distributions.

## My Causal Effects
![](../figures/results_from_trial.png){width=100%}

## A Note on Causality

This code does not estimate causal effects directly. This is a Bayesian regression model, but it only captures associations, not causal effects.




## Conjoint Experiment through Survey

I ran a conjoint experiment through a survey using Discover Sawtooth Software. I was testing how desirable different package deals (with specified benefits) were for different loyalty cards. I got 33 responses. Here are my results:

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Ever%20been%20on%20a%20plane_%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Employed%20rn_%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%2018_plus_%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20How%20often%20do%20you%20fly_%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Travel%20Reason_%20Chart.png)

##

![DAG](../figures/Loyalty%20Card%20Package%20Options%20-%20Card%20Type%20Chart.png)

##

![DAG](../figures/Loyalty%20Card%20Package%20Options%20-%20Benefit%201%20Chart.png)

##

![DAG](../figures/Loyalty%20Card%20Package%20Options%20-%20Benefit%202%20Chart.png)

##

![DAG](../figures/Loyalty%20Card%20Package%20Options%20-%20Price%20Chart.png)

##

![DAG](../figures/Loyalty%20Card%20Package%20Options%20-%20Attribute%20importance%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Buy%20a%20card_%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Yearly%20Income%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Education%20Level%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Age%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Gender%20Chart.png)

##

![DAG](../figures/Airline%20Loyalty%20Conjoint%20Survey%20-%20Married_%20Chart.png)


## Implement Diff-in-Diff Strategy

```{python}
#| eval: false
import arviz as az
import numpy as np
import pandas as pd
import pymc as pm
import seaborn as sns

# Outcomes

def outcome(t, control_intercept, treat_intercept_delta, trend, Δ, group, treated):
    return control_intercept + (treat_intercept_delta * group) + (trend * t) + (Δ * treated * group)

def is_treated(t, intervention_time, group):
    return (t > intervention_time) * group

# True parameters
control_intercept = 5000  # CLV for non-members
baseline_treat_intercept = 6000  # CLV for Aurora before upgrade
trend = 3000  # General CLV increase over time
Δ = 2000  # Treatment effect: additional CLV boost from upgrading to Star
intervention_time = 0.5  # When the upgrade happens

# Generating Synthetic Dataset
df = pd.DataFrame(
    {
        "group": [0, 0, 1, 1] * 10,  # 0 = No Loyalty Card, 1 = Aurora
        "t": [0.0, 1.0, 0.0, 1.0] * 10,  # Time periods (Pre/Post)
        "unit": np.concatenate([[i] * 2 for i in range(20)]),
    }
)

df["treated"] = is_treated(df["t"], intervention_time, df["group"])

df["y"] = outcome(
    df["t"],
    control_intercept,
    baseline_treat_intercept - control_intercept,  # Initial difference in CLV
    trend,
    Δ,
    df["group"],
    df["treated"],
)
df["y"] += np.random.normal(0, 500, df.shape[0])  # Add noise

# Frequentist Diff-in-Diff Calculation
diff_control = (
    df.loc[(df["t"] == 1) & (df["group"] == 0)]["y"].mean()
    - df.loc[(df["t"] == 0) & (df["group"] == 0)]["y"].mean()
)
print(f"Pre/post difference in control group = {diff_control:.2f}")

diff_treat = (
    df.loc[(df["t"] == 1) & (df["group"] == 1)]["y"].mean()
    - df.loc[(df["t"] == 0) & (df["group"] == 1)]["y"].mean()
)

print(f"Pre/post difference in treatment group = {diff_treat:.2f}")

diff_in_diff = diff_treat - diff_control
print(f"Difference in differences = {diff_in_diff:.2f}")

# Bayesian Approach
with pm.Model() as model:
    # Data
    t = pm.MutableData("t", df["t"].values, dims="obs_idx")
    treated = pm.MutableData("treated", df["treated"].values, dims="obs_idx")
    group = pm.MutableData("group", df["group"].values, dims="obs_idx")
    # Priors
    _control_intercept = pm.Normal("control_intercept", 5000, 1000)
    _treat_intercept_delta = pm.Normal("treat_intercept_delta", 1000, 1000)
    _trend = pm.Normal("trend", 3000, 1000)
    _Δ = pm.Normal("Δ", 2000, 1000)
    sigma = pm.HalfNormal("sigma", 500)
    # Expectation
    mu = pm.Deterministic(
        "mu",
        outcome(t, _control_intercept, _treat_intercept_delta, _trend, _Δ, group, treated),
        dims="obs_idx",
    )
    # Likelihood
    pm.Normal("obs", mu, sigma, observed=df["y"].values, dims="obs_idx")

with model:
    idata = pm.sample()

az.plot_trace(idata, var_names="~mu");



# Results
# Pre/post difference in control group = 3006.32
# Pre/post difference in treatment group = 4935.59
# Difference in differences = 1929.27
```

Those who upgraded to a higher loyalty status (aka got the treatment) had an increase of $1929.27 in CLV after they upgraded from an Aurora card to a higher status loyalty card.



## Matching Strategy

I implemented a matching strategy using propensity scores to see if getting a higher loyalty card (Star or Nova) caused an increase in CLV. I found a surprising result! Not only did it not increase CLV, it actually decreased CLV!

## Conclusion

